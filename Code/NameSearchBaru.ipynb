{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, TimeDistributed, Bidirectional, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keras import backend as K\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Podcast Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Total Episodes</th>\n",
       "      <th>Spotify URL</th>\n",
       "      <th>Cover Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>Easy Stories in English</td>\n",
       "      <td>Learning a language is hard, but Easy Stories ...</td>\n",
       "      <td>Ariel Goodbody, Polyglot English Teacher &amp; Gla...</td>\n",
       "      <td>216</td>\n",
       "      <td>https://open.spotify.com/show/23zdIqNUb0riR51w...</td>\n",
       "      <td>https://i.scdn.co/image/ab6765630000ba8a767693...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>Podcast Buku Kutu</td>\n",
       "      <td>EPISODE BARU SETIAP SENIN, RABU, dan JUMAT -- ...</td>\n",
       "      <td>Aditya Hadi - PODLUCK</td>\n",
       "      <td>162</td>\n",
       "      <td>https://open.spotify.com/show/3w5zKrbQ6kgB0RKI...</td>\n",
       "      <td>https://i.scdn.co/image/ab6765630000ba8a04fa1a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>Underwood and Flinch and Other Audiobooks by M...</td>\n",
       "      <td>Underwood and Flinch is a three-time Parsec aw...</td>\n",
       "      <td>Mike Bennett</td>\n",
       "      <td>244</td>\n",
       "      <td>https://open.spotify.com/show/3VwIE3bG0zpTCNzR...</td>\n",
       "      <td>https://i.scdn.co/image/ab6765630000ba8a4e7b42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>Podcast Resensi Buku</td>\n",
       "      <td>Kumpulan resensi beragam buku berbagai genre d...</td>\n",
       "      <td>Podcast Resensi Buku - PODLUCK</td>\n",
       "      <td>264</td>\n",
       "      <td>https://open.spotify.com/show/6woLsDl6CSntzeWU...</td>\n",
       "      <td>https://i.scdn.co/image/ab6765630000ba8a1e97ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts and entertainment</td>\n",
       "      <td>SupremeMasterTV</td>\n",
       "      <td>Supreme Master Television is an international ...</td>\n",
       "      <td>SupremeMasterTV</td>\n",
       "      <td>500</td>\n",
       "      <td>https://open.spotify.com/show/5bCgERRINgZWhauS...</td>\n",
       "      <td>https://i.scdn.co/image/ab6765630000ba8a7899e5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Genre                                       Podcast Name  \\\n",
       "0  arts and entertainment                            Easy Stories in English   \n",
       "1  arts and entertainment                                  Podcast Buku Kutu   \n",
       "2  arts and entertainment  Underwood and Flinch and Other Audiobooks by M...   \n",
       "3  arts and entertainment                               Podcast Resensi Buku   \n",
       "4  arts and entertainment                                    SupremeMasterTV   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Learning a language is hard, but Easy Stories ...   \n",
       "1  EPISODE BARU SETIAP SENIN, RABU, dan JUMAT -- ...   \n",
       "2  Underwood and Flinch is a three-time Parsec aw...   \n",
       "3  Kumpulan resensi beragam buku berbagai genre d...   \n",
       "4  Supreme Master Television is an international ...   \n",
       "\n",
       "                                           Publisher  Total Episodes  \\\n",
       "0  Ariel Goodbody, Polyglot English Teacher & Gla...             216   \n",
       "1                              Aditya Hadi - PODLUCK             162   \n",
       "2                                       Mike Bennett             244   \n",
       "3                     Podcast Resensi Buku - PODLUCK             264   \n",
       "4                                    SupremeMasterTV             500   \n",
       "\n",
       "                                         Spotify URL  \\\n",
       "0  https://open.spotify.com/show/23zdIqNUb0riR51w...   \n",
       "1  https://open.spotify.com/show/3w5zKrbQ6kgB0RKI...   \n",
       "2  https://open.spotify.com/show/3VwIE3bG0zpTCNzR...   \n",
       "3  https://open.spotify.com/show/6woLsDl6CSntzeWU...   \n",
       "4  https://open.spotify.com/show/5bCgERRINgZWhauS...   \n",
       "\n",
       "                                     Cover Image URL  \n",
       "0  https://i.scdn.co/image/ab6765630000ba8a767693...  \n",
       "1  https://i.scdn.co/image/ab6765630000ba8a04fa1a...  \n",
       "2  https://i.scdn.co/image/ab6765630000ba8a4e7b42...  \n",
       "3  https://i.scdn.co/image/ab6765630000ba8a1e97ef...  \n",
       "4  https://i.scdn.co/image/ab6765630000ba8a7899e5...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '../Data/podcasts_data.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acak urutan baris\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have the stopwords for both English and Indonesian\n",
    "stop_words = set(stopwords.words('english')).union(set(stopwords.words('indonesian')))\n",
    "\n",
    "# Cleaning 'Podcast Name' column\n",
    "dataset['Podcast Name'] = dataset['Podcast Name'].str.lower()  # Convert to lowercase\n",
    "dataset['Podcast Name'] = dataset['Podcast Name'].str.replace(r'[^\\w\\s]', '', regex=True)  # Remove punctuation\n",
    "dataset['Podcast Name'] = dataset['Podcast Name'].str.replace(r'\\d+', '', regex=True)  # Remove numbers\n",
    "dataset['Podcast Name'] = dataset['Podcast Name'].str.replace(r'\\s+', ' ', regex=True)  # Remove extra whitespace\n",
    "dataset['Podcast Name'] = dataset['Podcast Name'].str.strip()  # Remove leading and trailing whitespace\n",
    "dataset['Podcast Name'] = dataset['Podcast Name'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))  # Remove stop words\n",
    "\n",
    "# Cleaning 'Genre' column\n",
    "dataset['Genre'] = dataset['Genre'].str.lower()  # Convert to lowercase\n",
    "dataset['Genre'] = dataset['Genre'].str.replace(r'[^\\w\\s]', '', regex=True)  # Remove punctuation\n",
    "dataset['Genre'] = dataset['Genre'].str.replace(r'\\d+', '', regex=True)  # Remove numbers\n",
    "dataset['Genre'] = dataset['Genre'].str.replace(r'\\s+', ' ', regex=True)  # Remove extra whitespace\n",
    "dataset['Genre'] = dataset['Genre'].str.strip()  # Remove leading and trailing whitespace\n",
    "dataset['Genre'] = dataset['Genre'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))  # Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'Podcast Name' column\n",
    "podcast_data = dataset.dropna(subset=['Podcast Name'])\n",
    "\n",
    "# Extract podcast names\n",
    "podcast_names = podcast_data['Podcast Name'].values\n",
    "\n",
    "# Extract relevant columns\n",
    "podcast_names = podcast_data['Podcast Name'].values\n",
    "podcast_genres = podcast_data['Genre'].values\n",
    "podcast_descriptions = podcast_data['Description'].values\n",
    "podcast_publishers = podcast_data['Publisher'].values\n",
    "podcast_spotify_urls = podcast_data['Spotify URL'].values\n",
    "podcast_cover_image_urls = podcast_data['Cover Image URL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Vectorization\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(podcast_names)\n",
    "\n",
    "# Convert podcast names to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(podcast_names)\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Get the vocabulary size for the embedding layer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, padded_sequences, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 23, 128)           1150208   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 23, 256)          263168    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 23, 128)          164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 23, 128)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 23, 512)           66048     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 23, 8986)         4609818   \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,253,594\n",
      "Trainable params: 6,253,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation = 'relu'),\n",
    "    TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "106/106 [==============================] - 26s 84ms/step - loss: 2.0541 - accuracy: 0.8622 - val_loss: 1.0776 - val_accuracy: 0.8721\n",
      "Epoch 2/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 1.0485 - accuracy: 0.8707 - val_loss: 1.0209 - val_accuracy: 0.8747\n",
      "Epoch 3/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.9858 - accuracy: 0.8761 - val_loss: 0.9622 - val_accuracy: 0.8793\n",
      "Epoch 4/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.9188 - accuracy: 0.8787 - val_loss: 0.9048 - val_accuracy: 0.8806\n",
      "Epoch 5/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.8630 - accuracy: 0.8811 - val_loss: 0.8734 - val_accuracy: 0.8842\n",
      "Epoch 6/20\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 0.8214 - accuracy: 0.8828 - val_loss: 0.8527 - val_accuracy: 0.8851\n",
      "Epoch 7/20\n",
      "106/106 [==============================] - 8s 75ms/step - loss: 0.7787 - accuracy: 0.8844 - val_loss: 0.8159 - val_accuracy: 0.8887\n",
      "Epoch 8/20\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 0.7256 - accuracy: 0.8871 - val_loss: 0.7687 - val_accuracy: 0.8926\n",
      "Epoch 9/20\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 0.6696 - accuracy: 0.8907 - val_loss: 0.7237 - val_accuracy: 0.8964\n",
      "Epoch 10/20\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 0.6227 - accuracy: 0.8939 - val_loss: 0.6820 - val_accuracy: 0.9015\n",
      "Epoch 11/20\n",
      "106/106 [==============================] - 8s 74ms/step - loss: 0.5834 - accuracy: 0.8962 - val_loss: 0.6495 - val_accuracy: 0.9049\n",
      "Epoch 12/20\n",
      "106/106 [==============================] - 8s 75ms/step - loss: 0.5500 - accuracy: 0.8988 - val_loss: 0.6252 - val_accuracy: 0.9080\n",
      "Epoch 13/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.5193 - accuracy: 0.9014 - val_loss: 0.5932 - val_accuracy: 0.9118\n",
      "Epoch 14/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.4879 - accuracy: 0.9044 - val_loss: 0.5609 - val_accuracy: 0.9159\n",
      "Epoch 15/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.4592 - accuracy: 0.9080 - val_loss: 0.5360 - val_accuracy: 0.9198\n",
      "Epoch 16/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.4287 - accuracy: 0.9113 - val_loss: 0.5100 - val_accuracy: 0.9245\n",
      "Epoch 17/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.4036 - accuracy: 0.9144 - val_loss: 0.4855 - val_accuracy: 0.9278\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.3772 - accuracy: 0.9183 - val_loss: 0.4629 - val_accuracy: 0.9331\n",
      "Epoch 19/20\n",
      "106/106 [==============================] - 8s 73ms/step - loss: 0.3546 - accuracy: 0.9215 - val_loss: 0.4400 - val_accuracy: 0.9378\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - 8s 72ms/step - loss: 0.3308 - accuracy: 0.9254 - val_loss: 0.4216 - val_accuracy: 0.9412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb27df9b70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare labels to match the output shape of the model\n",
    "labels = np.expand_dims(padded_sequences, axis=-1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences, labels, epochs=20, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/time_distributed/dense_1/Softmax' defined at (most recent call last):\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_21244\\3067214628.py\", line 2, in <module>\n      y_pred_test = model.predict(X_test)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\layers\\rnn\\time_distributed.py\", line 252, in call\n      y = self.layer(inputs, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\activations.py\", line 84, in softmax\n      output = tf.nn.softmax(x, axis=axis)\nNode: 'sequential/time_distributed/dense_1/Softmax'\nOOM when allocating tensor with shape[736,8986] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/time_distributed/dense_1/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_25471]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y_pred_test_reshaped \u001b[38;5;241m=\u001b[39m y_pred_test\u001b[38;5;241m.\u001b[39mreshape(y_pred_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/time_distributed/dense_1/Softmax' defined at (most recent call last):\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_21244\\3067214628.py\", line 2, in <module>\n      y_pred_test = model.predict(X_test)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\layers\\rnn\\time_distributed.py\", line 252, in call\n      y = self.layer(inputs, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 255, in call\n      outputs = self.activation(outputs)\n    File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\keras\\activations.py\", line 84, in softmax\n      output = tf.nn.softmax(x, axis=axis)\nNode: 'sequential/time_distributed/dense_1/Softmax'\nOOM when allocating tensor with shape[736,8986] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/time_distributed/dense_1/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_25471]"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_test_reshaped = y_pred_test.reshape(y_pred_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved succesfully\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')\n",
    "print('Model saved succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:46:40.807131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "usage: TensorFlow.js model converters. [-h]\n",
      "                                       [--input_format {keras_saved_model,tf_hub,tf_saved_model,keras,tf_frozen_model,tfjs_layers_model}]\n",
      "                                       [--output_format {keras_saved_model,tfjs_graph_model,keras,tfjs_layers_model}]\n",
      "                                       [--signature_name SIGNATURE_NAME]\n",
      "                                       [--saved_model_tags SAVED_MODEL_TAGS]\n",
      "                                       [--quantize_float16 [QUANTIZE_FLOAT16]]\n",
      "                                       [--quantize_uint8 [QUANTIZE_UINT8]]\n",
      "                                       [--quantize_uint16 [QUANTIZE_UINT16]]\n",
      "                                       [--quantization_bytes {1,2}]\n",
      "                                       [--split_weights_by_layer] [--version]\n",
      "                                       [--skip_op_check]\n",
      "                                       [--strip_debug_ops STRIP_DEBUG_OPS]\n",
      "                                       [--use_structured_outputs_names USE_STRUCTURED_OUTPUTS_NAMES]\n",
      "                                       [--weight_shard_size_bytes WEIGHT_SHARD_SIZE_BYTES]\n",
      "                                       [--output_node_names OUTPUT_NODE_NAMES]\n",
      "                                       [--control_flow_v2 CONTROL_FLOW_V2]\n",
      "                                       [--experiments EXPERIMENTS]\n",
      "                                       [--metadata METADATA]\n",
      "                                       [input_path] [output_path]\n",
      "TensorFlow.js model converters.: error: unrecognized arguments: SMT 6\\Capstone\\PRODUCT\\Capstone-project-podpicks\\Code\\model.h5 D:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\Capstone-project-podpicks\\Code\\tfjs_model\n"
     ]
    }
   ],
   "source": [
    "#Run on terminal!\n",
    "!tensorflowjs_converter --input_format=keras --output_format=tfjs_layers_model \"D:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\Capstone-project-podpicks\\Code\\model.h5\" \"D:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\Capstone-project-podpicks\\Code\\tfjs_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 42ms/step\n",
      "16/16 [==============================] - 1s 47ms/step\n",
      "16/16 [==============================] - 1s 44ms/step\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "16/16 [==============================] - 1s 73ms/step\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "16/16 [==============================] - 1s 46ms/step\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "16/16 [==============================] - 1s 47ms/step\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "16/16 [==============================] - 1s 47ms/step\n",
      "16/16 [==============================] - 1s 46ms/step\n",
      "16/16 [==============================] - 1s 46ms/step\n",
      "16/16 [==============================] - 1s 44ms/step\n",
      "16/16 [==============================] - 1s 51ms/step\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "16/16 [==============================] - 1s 45ms/step\n",
      "16/16 [==============================] - 1s 44ms/step\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "15/15 [==============================] - 1s 44ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Prepare the embeddings for the podcasts\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m podcast_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_podcast_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_sequences\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m, in \u001b[0;36mget_podcast_embeddings\u001b[1;34m(model, data, batch_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m batch_embeddings\u001b[38;5;241m.\u001b[39mreshape(batch_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embeddings)\n\u001b[1;32m----> 8\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32md:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_podcast_embeddings(model, data, batch_size=512):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch_data = data[i:i + batch_size]\n",
    "        batch_embeddings = model.predict(batch_data)\n",
    "        batch_embeddings = batch_embeddings.reshape(batch_embeddings.shape[0], -1)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# Prepare the embeddings for the podcasts\n",
    "podcast_embeddings = get_podcast_embeddings(model, padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_podcasts(query, top_k=5):\n",
    "    # Tokenize and pad the query\n",
    "    query_sequence = tokenizer.texts_to_sequences([query])\n",
    "    query_padded = pad_sequences(query_sequence, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Encode the query using the trained model\n",
    "    query_embedding = model.predict(query_padded)\n",
    "    query_embedding = query_embedding.reshape(1, -1)\n",
    "    cosine_scores = cosine_similarity(query_embedding, podcast_embeddings)\n",
    "\n",
    "    # Get the top_k similar podcasts\n",
    "    top_k_indices = np.argsort(cosine_scores[0])[-top_k:][::-1]\n",
    "\n",
    "    # Retrieve the corresponding podcast names\n",
    "    similar_podcasts = [{\n",
    "        'Name': podcast_names[idx],\n",
    "        'Genre': podcast_genres[idx],\n",
    "        #'Description': podcast_descriptions[idx],\n",
    "        'Publisher': podcast_publishers[idx],\n",
    "        'Spotify URL': podcast_spotify_urls[idx],\n",
    "        'Cover Image URL': podcast_cover_image_urls[idx]\n",
    "    } for idx in top_k_indices]\n",
    "\n",
    "    return similar_podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[{'Name': 'epiphantastic', 'Genre': 'health', 'Publisher': 'Shrestha S Bharadwaj', 'Spotify URL': 'https://open.spotify.com/show/6Jyd77b4lV8hQ2zqBdFEQf', 'Cover Image URL': 'https://i.scdn.co/image/ab6765630000ba8ac105f22d2145df57bb060798'}, {'Name': 'epiphantastic', 'Genre': 'lifestyle', 'Publisher': 'Shrestha S Bharadwaj', 'Spotify URL': 'https://open.spotify.com/show/6Jyd77b4lV8hQ2zqBdFEQf', 'Cover Image URL': 'https://i.scdn.co/image/ab6765630000ba8ac105f22d2145df57bb060798'}, {'Name': 'epiphantastic', 'Genre': 'books', 'Publisher': 'Shrestha S Bharadwaj', 'Spotify URL': 'https://open.spotify.com/show/6Jyd77b4lV8hQ2zqBdFEQf', 'Cover Image URL': 'https://i.scdn.co/image/ab6765630000ba8ac105f22d2145df57bb060798'}, {'Name': 'epiphantastic', 'Genre': 'selfcare', 'Publisher': 'Shrestha S Bharadwaj', 'Spotify URL': 'https://open.spotify.com/show/6Jyd77b4lV8hQ2zqBdFEQf', 'Cover Image URL': 'https://i.scdn.co/image/ab6765630000ba8ac105f22d2145df57bb060798'}, {'Name': 'joystix', 'Genre': 'video games', 'Publisher': 'Thomas Taylor, Dylan Hadley, Edward Turner, Jamie Arnold', 'Spotify URL': 'https://open.spotify.com/show/7rSpD6RCzUJpGGAdro4zCa', 'Cover Image URL': 'https://i.scdn.co/image/88f26e62a1212245c32e34809629dd7d09c5097a'}]\n"
     ]
    }
   ],
   "source": [
    "# Example search\n",
    "query = \"games\"\n",
    "similar_podcasts = search_podcasts(query)\n",
    "print(similar_podcasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved succesfully\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')\n",
    "print('Model saved succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 15:57:27.160703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2024-06-10 15:57:27.161587: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\Scripts\\tensorflowjs_converter.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\tensorflowjs\\__init__.py\", line 21, in <module>\n",
      "    from tensorflowjs import converters\n",
      "  File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\tensorflowjs\\converters\\__init__.py\", line 26, in <module>\n",
      "    from tensorflowjs.converters.jax_conversion import convert_jax\n",
      "  File \"d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\tensorflowjs\\converters\\jax_conversion.py\", line 20, in <module>\n",
      "    from jax.experimental.jax2tf import shape_poly\n",
      "ImportError: cannot import name 'shape_poly' from 'jax.experimental.jax2tf' (d:\\Kuliah Stuff\\Kuliah SMT 6\\Capstone\\PRODUCT\\.venv\\lib\\site-packages\\jax\\experimental\\jax2tf\\__init__.py)\n"
     ]
    }
   ],
   "source": [
    "#Run on terminal!\n",
    "!tensorflowjs_converter --input_format=keras --output_format=tfjs_layers_model \"D:\\PodPicks\\Code\\model.h5\" \"D:\\PodPicks\\Code\\tfjs_model\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
