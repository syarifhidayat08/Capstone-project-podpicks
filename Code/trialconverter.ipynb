{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.4-py3-none-any.whl (5.1 MB)\n",
      "                                              0.0/5.1 MB ? eta -:--:--\n",
      "                                              0.0/5.1 MB ? eta -:--:--\n",
      "                                              0.0/5.1 MB ? eta -:--:--\n",
      "                                              0.0/5.1 MB 217.9 kB/s eta 0:00:24\n",
      "                                              0.1/5.1 MB 416.7 kB/s eta 0:00:12\n",
      "     -                                        0.2/5.1 MB 1.1 MB/s eta 0:00:05\n",
      "     ----                                     0.6/5.1 MB 2.3 MB/s eta 0:00:02\n",
      "     ---------                                1.2/5.1 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------                            1.7/5.1 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------                          1.9/5.1 MB 5.1 MB/s eta 0:00:01\n",
      "     ----------------                         2.1/5.1 MB 4.9 MB/s eta 0:00:01\n",
      "     -----------------                        2.2/5.1 MB 4.9 MB/s eta 0:00:01\n",
      "     -----------------                        2.3/5.1 MB 4.7 MB/s eta 0:00:01\n",
      "     -----------------                        2.3/5.1 MB 4.7 MB/s eta 0:00:01\n",
      "     -----------------                        2.3/5.1 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------                       2.4/5.1 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------                    2.7/5.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------                   2.8/5.1 MB 4.0 MB/s eta 0:00:01\n",
      "     --------------------------               3.3/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------              3.5/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "     ----------------------------             3.6/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------           3.8/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------          4.0/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------------         4.1/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "     ----------------------------------       4.3/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "     -----------------------------------      4.5/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     4.6/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------------    4.8/5.1 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------------   4.8/5.1 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------------   4.9/5.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.0/5.1 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.1/5.1 MB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl (101 kB)\n",
      "                                              0.0/101.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 101.3/101.3 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting etils[enp,epath,etree]>=0.9.0 (from tensorflow_datasets)\n",
      "  Downloading etils-1.8.0-py3-none-any.whl (156 kB)\n",
      "                                              0.0/156.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 156.1/156.1 kB 9.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_datasets) (1.26.4)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_datasets) (4.25.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\acer\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow_datasets) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Collecting tqdm (from tensorflow_datasets)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "                                              0.0/78.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: wrapt in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Collecting fsspec (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "                                              0.0/316.1 kB ? eta -:--:--\n",
      "     ------------------------------------   307.2/316.1 kB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 316.1/316.1 kB 9.9 MB/s eta 0:00:00\n",
      "Collecting importlib_resources (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.10.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\roaming\\python\\python311\\site-packages (from click->tensorflow_datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\acer\\appdata\\roaming\\python\\python311\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "                                              0.0/229.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 229.1/229.1 kB 6.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21544 sha256=0b093b7e155f7aec450b7a7f9e0ae8433ae93dc8ec16f203830679e127e5ffa5\n",
      "  Stored in directory: c:\\users\\acer\\appdata\\local\\pip\\cache\\wheels\\90\\74\\b1\\9b54c896b8d9409e9268329d4d45ede8a8040abe91c8879932\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, tqdm, promise, importlib_resources, googleapis-common-protos, fsspec, etils, tensorflow-metadata, tensorflow_datasets\n",
      "Successfully installed dm-tree-0.1.8 etils-1.8.0 fsspec-2024.5.0 googleapis-common-protos-1.63.0 importlib_resources-6.4.0 promise-2.3 tensorflow-metadata-1.15.0 tensorflow_datasets-4.9.4 tqdm-4.66.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install tensorflow\n",
    "#%pip install keras\n",
    "#%pip install numpy\n",
    "#%pip install numpy\n",
    "#%pip install pandas\n",
    "#%pip install scikit-learn\n",
    "#%pip install h5py\n",
    "#%pip install os\n",
    "#%pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert h5 file to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Capstone\\.conda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m385\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m385\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture saved to simple_model.json\n",
      "Model weights saved to simple_model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(10,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Save the model architecture to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"simple_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"Model architecture saved to simple_model.json\")\n",
    "\n",
    "model.save_weights(\"simple_model.weights.h5\")\n",
    "\n",
    "print(\"Model weights saved to simple_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD MODEL (JSON + WEIGHTS(H5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disk.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Load JSON and create model\n",
    "with open('simple_model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('simple_model.weights.h5')\n",
    "\n",
    "print(\"Model loaded from disk.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTOH INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction: [[0.4996243]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example input\n",
    "sample_input = np.random.rand(1, 10)  # Generate random input data of shape (1, 10)\n",
    "\n",
    "# Predict with the loaded model\n",
    "prediction = model.predict(sample_input)\n",
    "\n",
    "print(\"Prediction:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
